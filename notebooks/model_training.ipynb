{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MBTPy**\n",
    "---\n",
    "model_training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro - overview of the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toino\\anaconda3\\envs\\MBTPy_env\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n",
      "c:\\Users\\toino\\anaconda3\\envs\\MBTPy_env\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    8675 non-null   object\n",
      " 1   posts   8675 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 135.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data=pd.read_csv('../data/raw/mbti_1.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6940, 2)\n",
      "(1735, 2)\n"
     ]
    }
   ],
   "source": [
    "# Stratify split to ensure equal distribution of data\n",
    "train_data,test_data=train_test_split(data,test_size=0.2,random_state=42,stratify=data.type)\n",
    "print(train_data.shape, test_data.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6940/6940 [00:01<00:00, 3596.80it/s]\n",
      "100%|██████████| 6940/6940 [00:01<00:00, 3608.02it/s]\n",
      "100%|██████████| 1735/1735 [00:00<00:00, 3573.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing functions\n",
    "\n",
    "def clean_text(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    cleaned_text=[]\n",
    "    for sentence in tqdm(text):\n",
    "        sentence=sentence.lower()\n",
    "        sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n",
    "        sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "        cleaned_text.append(sentence)\n",
    "    return cleaned_text\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     return [lemmatizer.lemmatize(word) for word in text.split() if len(word)>2]\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('clean_text', FunctionTransformer(clean_text, validate=False)),\n",
    "    # ('lemmatize', FunctionTransformer(lemmatize_text, validate=False)),\n",
    "    ('vectorizer', TfidfVectorizer(max_features=5000, stop_words='english')),\n",
    "])\n",
    "\n",
    "\n",
    "# Fitting the preprocessing pipeline on the training text\n",
    "preprocessing_pipeline.fit(train_data['posts'])\n",
    "\n",
    "# Saving the pipeline\n",
    "joblib.dump(preprocessing_pipeline, '../models/preprocessing_pipeline.joblib')\n",
    "\n",
    "# Using the preprocessing pipeline to preprocess the data\n",
    "train_post = preprocessing_pipeline.transform(train_data['posts'])\n",
    "test_post = preprocessing_pipeline.transform(test_data['posts'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LabelEncoder to encode the target variable\n",
    "\n",
    "# Define the label encoder\n",
    "target_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "target_encoder.fit(train_data.type)\n",
    "\n",
    "# Save the encoder\n",
    "joblib.dump(target_encoder, '../models/target_encoder.joblib')\n",
    "\n",
    "# Use the encoder to preprocess the target\n",
    "train_target = target_encoder.transform(train_data.type)\n",
    "test_target = target_encoder.transform(test_data.type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_accuracy={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.83      0.16      0.27       152\n",
      "        ENFP       0.81      0.65      0.72       540\n",
      "        ENTJ       0.93      0.29      0.44       185\n",
      "        ENTP       0.81      0.68      0.74       548\n",
      "        ESFJ       0.00      0.00      0.00        33\n",
      "        ESFP       0.00      0.00      0.00        38\n",
      "        ESTJ       0.00      0.00      0.00        31\n",
      "        ESTP       1.00      0.04      0.08        71\n",
      "        INFJ       0.74      0.83      0.78      1176\n",
      "        INFP       0.66      0.93      0.77      1466\n",
      "        INTJ       0.75      0.81      0.78       873\n",
      "        INTP       0.69      0.87      0.77      1043\n",
      "        ISFJ       0.92      0.26      0.41       133\n",
      "        ISFP       0.87      0.24      0.38       217\n",
      "        ISTJ       0.84      0.25      0.38       164\n",
      "        ISTP       0.87      0.51      0.64       270\n",
      "\n",
      "    accuracy                           0.72      6940\n",
      "   macro avg       0.67      0.41      0.45      6940\n",
      "weighted avg       0.74      0.72      0.70      6940\n",
      "\n",
      "test classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       1.00      0.11      0.19        38\n",
      "        ENFP       0.76      0.55      0.64       135\n",
      "        ENTJ       0.78      0.15      0.25        46\n",
      "        ENTP       0.67      0.51      0.58       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.65      0.71      0.68       294\n",
      "        INFP       0.56      0.88      0.68       366\n",
      "        INTJ       0.62      0.67      0.64       218\n",
      "        INTP       0.65      0.81      0.72       261\n",
      "        ISFJ       0.80      0.12      0.21        33\n",
      "        ISFP       0.82      0.17      0.28        54\n",
      "        ISTJ       0.60      0.07      0.13        41\n",
      "        ISTP       0.72      0.43      0.54        67\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.54      0.32      0.35      1735\n",
      "weighted avg       0.64      0.63      0.59      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model_log=LogisticRegression(max_iter=3000,C=0.5,n_jobs=-1)\n",
    "model_log.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_log.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n',classification_report(test_target,model_log.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['logistic regression']=accuracy_score(test_target,model_log.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.91      0.45      0.61       152\n",
      "        ENFP       0.85      0.77      0.81       540\n",
      "        ENTJ       0.93      0.64      0.76       185\n",
      "        ENTP       0.84      0.82      0.83       548\n",
      "        ESFJ       0.92      0.33      0.49        33\n",
      "        ESFP       1.00      0.16      0.27        38\n",
      "        ESTJ       1.00      0.32      0.49        31\n",
      "        ESTP       0.91      0.44      0.59        71\n",
      "        INFJ       0.83      0.86      0.85      1176\n",
      "        INFP       0.77      0.93      0.85      1466\n",
      "        INTJ       0.83      0.86      0.85       873\n",
      "        INTP       0.81      0.90      0.85      1043\n",
      "        ISFJ       0.92      0.68      0.78       133\n",
      "        ISFP       0.90      0.59      0.71       217\n",
      "        ISTJ       0.88      0.65      0.75       164\n",
      "        ISTP       0.90      0.81      0.86       270\n",
      "\n",
      "    accuracy                           0.82      6940\n",
      "   macro avg       0.89      0.64      0.71      6940\n",
      "weighted avg       0.83      0.82      0.82      6940\n",
      "\n",
      "test classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.67      0.21      0.32        38\n",
      "        ENFP       0.73      0.59      0.66       135\n",
      "        ENTJ       0.70      0.35      0.46        46\n",
      "        ENTP       0.60      0.55      0.57       137\n",
      "        ESFJ       1.00      0.33      0.50         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       1.00      0.12      0.22         8\n",
      "        ESTP       0.86      0.33      0.48        18\n",
      "        INFJ       0.68      0.71      0.69       294\n",
      "        INFP       0.62      0.86      0.72       366\n",
      "        INTJ       0.64      0.67      0.66       218\n",
      "        INTP       0.70      0.82      0.75       261\n",
      "        ISFJ       0.56      0.27      0.37        33\n",
      "        ISFP       0.82      0.33      0.47        54\n",
      "        ISTJ       0.79      0.27      0.40        41\n",
      "        ISTP       0.69      0.54      0.61        67\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.69      0.44      0.49      1735\n",
      "weighted avg       0.67      0.66      0.64      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classifier\n",
    "\n",
    "model_linear_svc=LinearSVC(C=0.1)\n",
    "model_linear_svc.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_linear_svc.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n',classification_report(test_target,model_linear_svc.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['Linear Support Vector classifier']=accuracy_score(test_target,model_linear_svc.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.97      0.86      0.91       152\n",
      "        ENFP       0.96      0.96      0.96       540\n",
      "        ENTJ       0.99      0.90      0.94       185\n",
      "        ENTP       0.95      0.96      0.96       548\n",
      "        ESFJ       1.00      0.58      0.73        33\n",
      "        ESFP       1.00      0.37      0.54        38\n",
      "        ESTJ       1.00      0.52      0.68        31\n",
      "        ESTP       1.00      0.83      0.91        71\n",
      "        INFJ       0.95      0.97      0.96      1176\n",
      "        INFP       0.93      0.98      0.96      1466\n",
      "        INTJ       0.96      0.97      0.96       873\n",
      "        INTP       0.95      0.98      0.96      1043\n",
      "        ISFJ       1.00      0.88      0.94       133\n",
      "        ISFP       0.97      0.90      0.94       217\n",
      "        ISTJ       0.94      0.91      0.93       164\n",
      "        ISTP       0.98      0.93      0.95       270\n",
      "\n",
      "    accuracy                           0.95      6940\n",
      "   macro avg       0.97      0.84      0.89      6940\n",
      "weighted avg       0.95      0.95      0.95      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.69      0.29      0.41        38\n",
      "        ENFP       0.75      0.57      0.65       135\n",
      "        ENTJ       0.71      0.26      0.38        46\n",
      "        ENTP       0.65      0.53      0.58       137\n",
      "        ESFJ       0.33      0.11      0.17         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.80      0.22      0.35        18\n",
      "        INFJ       0.68      0.69      0.68       294\n",
      "        INFP       0.58      0.86      0.69       366\n",
      "        INTJ       0.65      0.64      0.65       218\n",
      "        INTP       0.66      0.84      0.74       261\n",
      "        ISFJ       0.80      0.24      0.37        33\n",
      "        ISFP       0.78      0.33      0.47        54\n",
      "        ISTJ       0.79      0.27      0.40        41\n",
      "        ISTP       0.77      0.55      0.64        67\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.60      0.40      0.45      1735\n",
      "weighted avg       0.66      0.65      0.63      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "\n",
    "model_svc=SVC()\n",
    "model_svc.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_svc.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_svc.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['Support Vector classifier']=accuracy_score(test_target,model_svc.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00       152\n",
      "        ENFP       0.93      0.02      0.05       540\n",
      "        ENTJ       0.00      0.00      0.00       185\n",
      "        ENTP       0.92      0.08      0.15       548\n",
      "        ESFJ       0.00      0.00      0.00        33\n",
      "        ESFP       0.00      0.00      0.00        38\n",
      "        ESTJ       0.00      0.00      0.00        31\n",
      "        ESTP       0.00      0.00      0.00        71\n",
      "        INFJ       0.51      0.62      0.56      1176\n",
      "        INFP       0.36      0.93      0.52      1466\n",
      "        INTJ       0.78      0.44      0.56       873\n",
      "        INTP       0.59      0.65      0.62      1043\n",
      "        ISFJ       0.00      0.00      0.00       133\n",
      "        ISFP       0.00      0.00      0.00       217\n",
      "        ISTJ       0.00      0.00      0.00       164\n",
      "        ISTP       0.00      0.00      0.00       270\n",
      "\n",
      "    accuracy                           0.46      6940\n",
      "   macro avg       0.26      0.17      0.15      6940\n",
      "weighted avg       0.49      0.46      0.38      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       0.71      0.04      0.07       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.44      0.03      0.05       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.38      0.45      0.41       294\n",
      "        INFP       0.32      0.90      0.47       366\n",
      "        INTJ       0.70      0.21      0.32       218\n",
      "        INTP       0.52      0.54      0.53       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.38      1735\n",
      "   macro avg       0.19      0.14      0.12      1735\n",
      "weighted avg       0.39      0.38      0.30      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "model_multinomial_nb=MultinomialNB()\n",
    "model_multinomial_nb.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_multinomial_nb.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_multinomial_nb.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['Multinomial Naive Bayes']=accuracy_score(test_target,model_multinomial_nb.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.80      0.64      0.71       152\n",
      "        ENFP       0.89      0.82      0.86       540\n",
      "        ENTJ       0.90      0.70      0.78       185\n",
      "        ENTP       0.91      0.81      0.86       548\n",
      "        ESFJ       0.88      0.42      0.57        33\n",
      "        ESFP       0.80      0.21      0.33        38\n",
      "        ESTJ       0.73      0.35      0.48        31\n",
      "        ESTP       0.88      0.41      0.56        71\n",
      "        INFJ       0.83      0.86      0.84      1176\n",
      "        INFP       0.67      0.94      0.78      1466\n",
      "        INTJ       0.87      0.82      0.85       873\n",
      "        INTP       0.87      0.81      0.84      1043\n",
      "        ISFJ       0.97      0.56      0.71       133\n",
      "        ISFP       0.93      0.62      0.75       217\n",
      "        ISTJ       0.80      0.63      0.70       164\n",
      "        ISTP       0.95      0.71      0.81       270\n",
      "\n",
      "    accuracy                           0.81      6940\n",
      "   macro avg       0.85      0.65      0.71      6940\n",
      "weighted avg       0.83      0.81      0.81      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.13      0.08      0.10        38\n",
      "        ENFP       0.44      0.43      0.43       135\n",
      "        ENTJ       0.32      0.22      0.26        46\n",
      "        ENTP       0.44      0.44      0.44       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.25      0.06      0.09        18\n",
      "        INFJ       0.56      0.57      0.56       294\n",
      "        INFP       0.53      0.72      0.61       366\n",
      "        INTJ       0.54      0.50      0.52       218\n",
      "        INTP       0.60      0.59      0.59       261\n",
      "        ISFJ       0.33      0.21      0.26        33\n",
      "        ISFP       0.44      0.26      0.33        54\n",
      "        ISTJ       0.47      0.44      0.46        41\n",
      "        ISTP       0.52      0.45      0.48        67\n",
      "\n",
      "    accuracy                           0.51      1735\n",
      "   macro avg       0.35      0.31      0.32      1735\n",
      "weighted avg       0.50      0.51      0.50      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "model_tree=DecisionTreeClassifier(max_depth=14)\n",
    "model_tree.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_tree.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_tree.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['Decision Tree classifier']=accuracy_score(test_target,model_tree.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       1.00      0.01      0.01       152\n",
      "        ENFP       0.99      0.32      0.49       540\n",
      "        ENTJ       1.00      0.04      0.07       185\n",
      "        ENTP       0.99      0.46      0.62       548\n",
      "        ESFJ       0.00      0.00      0.00        33\n",
      "        ESFP       0.00      0.00      0.00        38\n",
      "        ESTJ       0.00      0.00      0.00        31\n",
      "        ESTP       0.00      0.00      0.00        71\n",
      "        INFJ       0.77      0.83      0.80      1176\n",
      "        INFP       0.44      1.00      0.61      1466\n",
      "        INTJ       0.88      0.73      0.80       873\n",
      "        INTP       0.81      0.85      0.83      1043\n",
      "        ISFJ       1.00      0.08      0.14       133\n",
      "        ISFP       1.00      0.06      0.12       217\n",
      "        ISTJ       1.00      0.05      0.09       164\n",
      "        ISTP       1.00      0.28      0.43       270\n",
      "\n",
      "    accuracy                           0.65      6940\n",
      "   macro avg       0.68      0.29      0.31      6940\n",
      "weighted avg       0.77      0.65      0.60      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.00      0.00      0.00        38\n",
      "        ENFP       1.00      0.04      0.09       135\n",
      "        ENTJ       0.00      0.00      0.00        46\n",
      "        ENTP       0.77      0.07      0.13       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.56      0.62      0.59       294\n",
      "        INFP       0.34      0.92      0.50       366\n",
      "        INTJ       0.69      0.46      0.55       218\n",
      "        INTP       0.60      0.57      0.59       261\n",
      "        ISFJ       0.00      0.00      0.00        33\n",
      "        ISFP       0.00      0.00      0.00        54\n",
      "        ISTJ       0.00      0.00      0.00        41\n",
      "        ISTP       0.88      0.10      0.19        67\n",
      "\n",
      "    accuracy                           0.46      1735\n",
      "   macro avg       0.30      0.17      0.16      1735\n",
      "weighted avg       0.52      0.46      0.39      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "model_forest=RandomForestClassifier(max_depth=10)\n",
    "model_forest.fit(train_post,train_target)\n",
    "\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_forest.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_forest.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['Random Forest Classifier']=accuracy_score(test_target,model_forest.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:31:14] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       1.00      0.95      0.98       152\n",
      "        ENFP       0.95      0.92      0.94       540\n",
      "        ENTJ       0.99      0.93      0.96       185\n",
      "        ENTP       0.96      0.93      0.95       548\n",
      "        ESFJ       1.00      0.97      0.98        33\n",
      "        ESFP       1.00      0.97      0.99        38\n",
      "        ESTJ       1.00      0.97      0.98        31\n",
      "        ESTP       1.00      0.97      0.99        71\n",
      "        INFJ       0.92      0.91      0.92      1176\n",
      "        INFP       0.90      0.95      0.92      1466\n",
      "        INTJ       0.93      0.92      0.93       873\n",
      "        INTP       0.91      0.93      0.92      1043\n",
      "        ISFJ       1.00      0.95      0.98       133\n",
      "        ISFP       1.00      0.93      0.96       217\n",
      "        ISTJ       0.99      0.96      0.97       164\n",
      "        ISTP       0.97      0.97      0.97       270\n",
      "\n",
      "    accuracy                           0.93      6940\n",
      "   macro avg       0.97      0.95      0.96      6940\n",
      "weighted avg       0.94      0.93      0.93      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.56      0.37      0.44        38\n",
      "        ENFP       0.70      0.59      0.64       135\n",
      "        ENTJ       0.62      0.33      0.43        46\n",
      "        ENTP       0.58      0.61      0.59       137\n",
      "        ESFJ       1.00      0.11      0.20         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       1.00      0.25      0.40         8\n",
      "        ESTP       0.60      0.33      0.43        18\n",
      "        INFJ       0.69      0.75      0.72       294\n",
      "        INFP       0.65      0.79      0.71       366\n",
      "        INTJ       0.67      0.65      0.66       218\n",
      "        INTP       0.67      0.76      0.71       261\n",
      "        ISFJ       0.64      0.42      0.51        33\n",
      "        ISFP       0.62      0.39      0.48        54\n",
      "        ISTJ       0.74      0.41      0.53        41\n",
      "        ISTP       0.66      0.60      0.62        67\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.65      0.46      0.50      1735\n",
      "weighted avg       0.66      0.66      0.65      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "\n",
    "# model_xgb=XGBClassifier(gpu_id=0,tree_method='gpu_hist',max_depth=5,n_estimators=50,learning_rate=0.1)\n",
    "model_xgb=XGBClassifier(max_depth=5,n_estimators=50,learning_rate=0.1)\n",
    "model_xgb.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_xgb.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_xgb.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['XGBoost Classifier']=accuracy_score(test_target,model_xgb.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.86      0.62      0.72       152\n",
      "        ENFP       0.85      0.79      0.82       540\n",
      "        ENTJ       0.89      0.66      0.76       185\n",
      "        ENTP       0.83      0.81      0.82       548\n",
      "        ESFJ       1.00      0.52      0.68        33\n",
      "        ESFP       1.00      0.39      0.57        38\n",
      "        ESTJ       1.00      0.39      0.56        31\n",
      "        ESTP       0.94      0.62      0.75        71\n",
      "        INFJ       0.83      0.87      0.85      1176\n",
      "        INFP       0.81      0.90      0.85      1466\n",
      "        INTJ       0.83      0.84      0.84       873\n",
      "        INTP       0.78      0.88      0.83      1043\n",
      "        ISFJ       0.91      0.70      0.79       133\n",
      "        ISFP       0.88      0.68      0.77       217\n",
      "        ISTJ       0.90      0.74      0.81       164\n",
      "        ISTP       0.90      0.80      0.85       270\n",
      "\n",
      "    accuracy                           0.83      6940\n",
      "   macro avg       0.89      0.70      0.77      6940\n",
      "weighted avg       0.83      0.83      0.83      6940\n",
      "\n",
      "test classification report \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.64      0.42      0.51        38\n",
      "        ENFP       0.71      0.66      0.68       135\n",
      "        ENTJ       0.77      0.52      0.62        46\n",
      "        ENTP       0.60      0.60      0.60       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       1.00      0.12      0.22         8\n",
      "        ESTP       0.67      0.22      0.33        18\n",
      "        INFJ       0.70      0.72      0.71       294\n",
      "        INFP       0.68      0.80      0.74       366\n",
      "        INTJ       0.66      0.67      0.66       218\n",
      "        INTP       0.66      0.78      0.71       261\n",
      "        ISFJ       0.70      0.48      0.57        33\n",
      "        ISFP       0.57      0.43      0.49        54\n",
      "        ISTJ       0.76      0.39      0.52        41\n",
      "        ISTP       0.66      0.66      0.66        67\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.61      0.47      0.50      1735\n",
      "weighted avg       0.67      0.67      0.66      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Classifier\n",
    "\n",
    "model_cat=CatBoostClassifier(loss_function='MultiClass',eval_metric='MultiClass',task_type='GPU',verbose=False)\n",
    "model_cat.fit(train_post,train_target)\n",
    "\n",
    "print('train classification report \\n ',classification_report(train_target,model_cat.predict(train_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "print('test classification report \\n ',classification_report(test_target,model_cat.predict(test_post),target_names=target_encoder.inverse_transform([i for i in range(16)])))\n",
    "\n",
    "models_accuracy['CatBoost Classifier']=accuracy_score(test_target,model_cat.predict(test_post))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_450b9_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_450b9_row1_col1 {\n",
       "  background-color: #083979;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_450b9_row2_col1 {\n",
       "  background-color: #083b7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_450b9_row3_col1 {\n",
       "  background-color: #084488;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_450b9_row4_col1 {\n",
       "  background-color: #0d57a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_450b9_row5_col1 {\n",
       "  background-color: #7ab6d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_450b9_row6_col1 {\n",
       "  background-color: #c2d9ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_450b9_row7_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_450b9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_450b9_level0_col0\" class=\"col_heading level0 col0\" >Models</th>\n",
       "      <th id=\"T_450b9_level0_col1\" class=\"col_heading level0 col1\" >Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_450b9_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_450b9_row0_col1\" class=\"data row0 col1\" >0.672046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_450b9_row1_col0\" class=\"data row1 col0\" >Linear Support Vector classifier</td>\n",
       "      <td id=\"T_450b9_row1_col1\" class=\"data row1 col1\" >0.661671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_450b9_row2_col0\" class=\"data row2 col0\" >XGBoost Classifier</td>\n",
       "      <td id=\"T_450b9_row2_col1\" class=\"data row2 col1\" >0.658790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_450b9_row3_col0\" class=\"data row3 col0\" >Support Vector classifier</td>\n",
       "      <td id=\"T_450b9_row3_col1\" class=\"data row3 col1\" >0.649568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_450b9_row4_col0\" class=\"data row4 col0\" >logistic regression</td>\n",
       "      <td id=\"T_450b9_row4_col1\" class=\"data row4 col1\" >0.628242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_450b9_row5_col0\" class=\"data row5 col0\" >Decision Tree classifier</td>\n",
       "      <td id=\"T_450b9_row5_col1\" class=\"data row5 col1\" >0.514697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_450b9_row6_col0\" class=\"data row6 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_450b9_row6_col1\" class=\"data row6 col1\" >0.455908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_450b9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_450b9_row7_col0\" class=\"data row7 col0\" >Multinomial Naive Bayes</td>\n",
       "      <td id=\"T_450b9_row7_col1\" class=\"data row7 col1\" >0.378098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dff86e71f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_accuracy\n",
    "\n",
    "models_accuracy.keys()\n",
    "\n",
    "accuracy=pd.DataFrame(models_accuracy.items(),columns=['Models','Test accuracy'])\n",
    "\n",
    "accuracy.sort_values(by='Test accuracy',ascending=False,ignore_index=True).style.background_gradient(cmap='Blues')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./models/model_log.joblib\n",
      "Model saved to ./models/model_linear_svc.joblib\n",
      "Model saved to ./models/model_svc.joblib\n",
      "Model saved to ./models/model_multinomial_nb.joblib\n",
      "Model saved to ./models/model_tree.joblib\n",
      "Model saved to ./models/model_forest.joblib\n",
      "Model saved to ./models/model_xgb.joblib\n",
      "Model saved to ./models/model_cat.joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "def export_models(models=[], path='../models/', active=False):\n",
    "    \"\"\"\n",
    "    Export trained models\n",
    "    - models : List of tuples (model, 'name')\n",
    "    - path : directory where to save files\n",
    "    - active : defines if the function should export models when called\n",
    "    \"\"\"\n",
    "    if active :\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        for model in models:\n",
    "            file_path = path + model[1] + '.joblib'\n",
    "            joblib.dump(model[0], file_path)\n",
    "            print(f'Model saved to {file_path}')\n",
    "\n",
    "\n",
    "\n",
    "models_list = [\n",
    "    (model_log, \"model_log\"), # Logistic Regression\n",
    "    (model_linear_svc, \"model_linear_svc\"), # Linear Support Vector Classifier\n",
    "    (model_svc, \"model_svc\"), # Support Vector Classifier\n",
    "    (model_multinomial_nb, \"model_multinomial_nb\"), # Multinomial Naive Bayes\n",
    "    (model_tree, \"model_tree\"), # Decision Tree Classifier\n",
    "    (model_forest, \"model_forest\"), # Random Forest Classifier\n",
    "    (model_xgb, \"model_xgb\"), # XGBoost Classifier\n",
    "    (model_cat, \"model_cat\"), # CatBoost Classifier\n",
    "]\n",
    "\n",
    "models_path = '../models/'\n",
    "\n",
    "export_models(models=models_list, path=models_path, active=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8340957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy.to_pickle('../models_accuracy.pkl')\n",
    "accuracy.to_csv('../results/models_accuracy.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5761040",
   "metadata": {},
   "source": [
    "## Test prediction (cc-temp)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "115fef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test - prediction from csv file (one model)\n",
    "\n",
    "# # Creating a new dataframe with the text data we want to test\n",
    "# new_data = pd.read_csv('../data/raw/new_data.csv')\n",
    "\n",
    "# # Loading the trained model and pipelines\n",
    "# model = joblib.load('../models/model_svc.joblib')\n",
    "# preprocessing_pipeline = joblib.load('../models/preprocessing_pipeline.joblib')\n",
    "# target_encoder = joblib.load('../models/target_encoder.joblib')\n",
    "\n",
    "# # Clean and preprocess the text data\n",
    "# new_post = preprocessing_pipeline.transform(new_data['posts'])\n",
    "\n",
    "# # Using the model to predict the personality type\n",
    "# prediction = model.predict(new_post)\n",
    "# print(target_encoder.inverse_transform(prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "115fef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INFP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test - prediction from dataframe (one model)\n",
    "\n",
    "# Creating a new dataframe with the text data we want to test\n",
    "new_data = pd.DataFrame({'posts':['World is a beautiful place full of amazing people and opportunities ! ||| Hello there !']})\n",
    "\n",
    "# Loading the trained model and pipelines\n",
    "model = joblib.load('../models/model_svc.joblib')\n",
    "preprocessing_pipeline = joblib.load('../models/preprocessing_pipeline.joblib')\n",
    "target_encoder = joblib.load('../models/target_encoder.joblib')\n",
    "\n",
    "# Clean and preprocess the text data\n",
    "new_post = preprocessing_pipeline.transform(new_data.posts)\n",
    "\n",
    "# Using the model to predict the personality type\n",
    "prediction = model.predict(new_post)\n",
    "print(target_encoder.inverse_transform(prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INFP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test - prediction from a list of text (one model)\n",
    "\n",
    "# new_data is the data we want to preprocess, it should be a list of text.\n",
    "new_data = [\"'World is a beautiful place full of amazing people and opportunities ! ||| Hello there !\"]\n",
    "\n",
    "# Loading the trained model and pipelines\n",
    "model = joblib.load('../models/model_svc.joblib')\n",
    "preprocessing_pipeline = joblib.load('../models/preprocessing_pipeline.joblib')\n",
    "target_encoder = joblib.load('../models/target_encoder.joblib')\n",
    "\n",
    "# Clean and preprocess the text data\n",
    "new_post = preprocessing_pipeline.transform(new_data)\n",
    "\n",
    "# Using the model to predict the personality type\n",
    "prediction = model.predict(new_post)\n",
    "print(target_encoder.inverse_transform(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - encoding new data\n",
    "\n",
    "new_target = [\"INFJ\"]\n",
    "# Load the saved pipeline\n",
    "target_encoder = joblib.load('../models/target_encoder.joblib')\n",
    "# Encoding new target variable\n",
    "encoded_target = target_encoder.transform(new_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: ['INTJ']\n",
      "Linear SVC: ['INTJ']\n",
      "SVC: ['INTJ']\n",
      "Multinomial NB: ['INFP']\n",
      "Decision Tree: ['INFP']\n",
      "Random Forest: ['INFP']\n",
      "XGBoost: ['INTP']\n",
      "CatBoost: ['INTP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test - prediction (all models)\n",
    "\n",
    "\n",
    "# Creating a new dataframe with the text data we want to test\n",
    "new_data = pd.DataFrame({'posts':['World is a beautiful place full of amazing people and opportunities ! ||| Hello there !']})\n",
    "\n",
    "preprocessing_pipeline = joblib.load('../models/preprocessing_pipeline.joblib')\n",
    "target_encoder = joblib.load('../models/target_encoder.joblib')\n",
    "\n",
    "\n",
    "def test_models(data, vectorizer, target_encoder):\n",
    "    models = [\n",
    "        joblib.load('../models/model_log.joblib'),\n",
    "        joblib.load('../models/model_linear_svc.joblib'),\n",
    "        joblib.load('../models/model_svc.joblib'),\n",
    "        joblib.load('../models/model_multinomial_nb.joblib'),\n",
    "        joblib.load('../models/model_tree.joblib'),\n",
    "        joblib.load('../models/model_forest.joblib'),\n",
    "        joblib.load('../models/model_xgb.joblib'),\n",
    "        joblib.load('../models/model_cat.joblib')\n",
    "    ]\n",
    "    model_names = [\n",
    "        'Logistic Regression',\n",
    "        'Linear SVC',\n",
    "        'SVC',\n",
    "        'Multinomial NB',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'XGBoost',\n",
    "        'CatBoost'\n",
    "    ]\n",
    "    new_post = preprocessing_pipeline.transform(new_data)\n",
    "    for i, model in enumerate(models):\n",
    "        prediction = model.predict(new_post)\n",
    "        print(f'{model_names[i]}: {target_encoder.inverse_transform(prediction)}')\n",
    "\n",
    "\n",
    "test_models(new_data, preprocessing_pipeline, target_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MBTPy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815978042b6fcd5f789cc9727fa79f4851188fba10d67f9360c50d4018f34090"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
